import random
import json
from datetime import datetime
from typing import Dict, List, Optional
import requests
from bs4 import BeautifulSoup
import re

from config.settings import *
from config.secrets_manager import SecretsManager

class ContentGenerator:
    def __init__(self, secrets_manager: SecretsManager):
        self.secrets = secrets_manager
        self.trending_topics = []
        self.last_trend_update = None
        
    def get_trending_topics(self, force_update=False):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ø¶ÙŠØ¹ ØªØ±Ù†Ø¯ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…Ø®ØªÙ„ÙØ© Ø¨Ø¯ÙˆÙ† API keys"""
        if (self.trending_topics and not force_update and 
            self.last_trend_update and 
            (datetime.now() - self.last_trend_update).hours < TREND_SETTINGS["update_frequency"]):
            return self.trending_topics
        
        topics = []
        
        try:
            # 1. Ù…Ù† Reddit (Ø¨Ø¯ÙˆÙ† API)
            reddit_topics = self._scrape_reddit_trends()
            topics.extend(reddit_topics)
            
            # 2. Ù…Ù† Google Trends (Ø¨Ø¯ÙˆÙ† API)
            google_topics = self._scrape_google_trends()
            topics.extend(google_topics)
            
            # 3. Ù…Ù† Twitter Trends (Ø¨Ø¯ÙˆÙ† API - Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Nitter)
            twitter_topics = self._scrape_twitter_trends()
            topics.extend(twitter_topics)
            
            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
            unique_topics = []
            seen = set()
            for topic in topics:
                if topic.lower() not in seen:
                    seen.add(topic.lower())
                    unique_topics.append(topic)
            
            self.trending_topics = unique_topics[:20]  # Ø§Ø­ØªÙØ¸ Ø¨Ù€ 20 ÙÙ‚Ø·
            self.last_trend_update = datetime.now()
            
        except Exception as e:
            print(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ØªØ±Ù†Ø¯Ø§Øª: {e}")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            if not self.trending_topics:
                self.trending_topics = [
                    "Artificial Intelligence", "Space Exploration", "Climate Change",
                    "World History", "Geography Facts", "Scientific Discoveries",
                    "Animal Kingdom", "Human Body", "Technology Innovations",
                    "Cultural Traditions", "Famous Landmarks", "Country Flags",
                    "Ocean Mysteries", "Ancient Civilizations", "Modern Inventions"
                ]
        
        return self.trending_topics
    
    def _scrape_reddit_trends(self):
        """Ø³Ø­Ø¨ ØªØ±Ù†Ø¯Ø§Øª Ù…Ù† Reddit"""
        topics = []
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            
            # subreddits Ø´Ø¹Ø¨ÙŠØ©
            subreddits = ['todayilearned', 'interestingasfuck', 'science', 'history']
            
            for sub in subreddits:
                url = f"https://old.reddit.com/r/{sub}/"
                response = requests.get(url, headers=headers, timeout=10)
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
                    for post in soup.find_all('a', class_='title', href=True):
                        title = post.text.strip()
                        if title and len(title) > 10:
                            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„ÙŠÙƒÙˆÙ† Ø³Ø¤Ø§Ù„Ø§Ù‹
                            question = self._convert_to_question(title)
                            if question:
                                topics.append(question)
                    
                    # Ø£Ø®Ø° Ø£ÙˆÙ„ 5 Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ù† ÙƒÙ„ subreddit
                    if len(topics) >= 5 * len(subreddits):
                        break
                        
        except Exception as e:
            print(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ Ø³Ø­Ø¨ Reddit: {e}")
        
        return topics[:10]
    
    def _scrape_google_trends(self):
        """Ø³Ø­Ø¨ ØªØ±Ù†Ø¯Ø§Øª Ù…Ù† Google Trends"""
        topics = []
        try:
            url = "https://trends.google.com/trends/trendingsearches/daily/rss?geo=US"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'xml')
                
                for item in soup.find_all('title')[1:6]:  # ØªØ®Ø·ÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ÙˆÙ„
                    title = item.text.strip()
                    if title:
                        question = self._convert_to_question(title)
                        if question:
                            topics.append(question)
                            
        except Exception as e:
            print(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ Ø³Ø­Ø¨ Google Trends: {e}")
        
        return topics
    
    def _scrape_twitter_trends(self):
        """Ø³Ø­Ø¨ ØªØ±Ù†Ø¯Ø§Øª Ù…Ù† Twitter Ø¹Ø¨Ø± Nitter"""
        topics = []
        try:
            url = "https://nitter.net"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                trend_section = soup.find('div', class_='trends')
                if trend_section:
                    for trend in trend_section.find_all('a', href=True)[:10]:
                        topic = trend.text.strip().replace('#', '')
                        if topic:
                            question = self._convert_to_question(topic)
                            if question:
                                topics.append(question)
                                
        except Exception as e:
            print(f"âš ï¸  Ø®Ø·Ø£ ÙÙŠ Ø³Ø­Ø¨ Twitter Trends: {e}")
        
        return topics
    
    def _convert_to_question(self, topic: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¥Ù„Ù‰ Ø³Ø¤Ø§Ù„"""
        topic_lower = topic.lower()
        
        question_templates = [
            "What do you know about {topic}?",
            "Can you identify this {topic}?",
            "Where can you find {topic}?",
            "When was {topic} discovered?",
            "How does {topic} work?",
            "Why is {topic} important?",
            "Which country is known for {topic}?",
            "What is the significance of {topic}?"
        ]
        
        # Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ù…Ù‡Ù…Ø©
        stop_words = ['the', 'a', 'an', 'this', 'that', 'these', 'those']
        words = [word for word in topic.split() if word.lower() not in stop_words]
        clean_topic = ' '.join(words[:5])  # Ø£Ø®Ø° Ø£ÙˆÙ„ 5 ÙƒÙ„Ù…Ø§Øª ÙÙ‚Ø·
        
        if len(clean_topic.split()) < 2:
            return None
        
        template = random.choice(question_templates)
        return template.format(topic=clean_topic)
    
    def generate_question(self) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ ÙƒØ§Ù…Ù„ Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙ‡"""
        question_type = random.choice(CONTENT_CONFIG["question_types"])
        difficulty = random.choice(CONTENT_CONFIG["difficulty_levels"])
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… AI Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹ØŒ ÙˆØ¥Ù„Ø§ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø­Ù„ÙŠØ©
        ai_question = self._generate_with_ai(question_type, difficulty)
        
        if ai_question:
            question_data = ai_question
        else:
            question_data = self._generate_local_question(question_type, difficulty)
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        question_data.update({
            "question_type": question_type,
            "difficulty": difficulty,
            "timestamp": datetime.now().isoformat(),
            "hashtags": self._generate_hashtags(question_type, difficulty)
        })
        
        return question_data
    
    def _generate_with_ai(self, q_type: str, difficulty: str) -> Optional[Dict]:
        """ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI APIs"""
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Gemini Ø£ÙˆÙ„Ø§Ù‹
        gemini_key = self.secrets.get_key("gemini", "api")
        if gemini_key:
            try:
                return self._call_gemini_api(q_type, difficulty, gemini_key)
            except:
                self.secrets.mark_failed(self.secrets.active_keys.get("gemini"))
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ OpenAI
        openai_key = self.secrets.get_key("openai", "api")
        if openai_key:
            try:
                return self._call_openai_api(q_type, difficulty, openai_key)
            except:
                self.secrets.mark_failed(self.secrets.active_keys.get("openai"))
        
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Groq
        groq_key = self.secrets.get_key("groq", "api")
        if groq_key:
            try:
                return self._call_groq_api(q_type, difficulty, groq_key)
            except:
                self.secrets.mark_failed("GROQ_API_KEY")
        
        return None
    
    def _call_gemini_api(self, q_type: str, difficulty: str, api_key: str) -> Dict:
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini API"""
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-pro')
        
        prompt = f"""Generate a {difficulty} {q_type} question for YouTube Shorts with:
        1. A clear question text
        2. Correct answer
        3. 3 wrong answers for multiple choice
        4. Brief explanation (max 10 words)
        5. Image description for background
        
        Format as JSON:
        {{
            "question": "text",
            "correct_answer": "text",
            "wrong_answers": ["a", "b", "c"],
            "explanation": "text",
            "image_description": "text"
        }}"""
        
        response = model.generate_content(prompt)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯ (Ù‡Ø°Ø§ Ù…Ø«Ø§Ù„ Ù…Ø¨Ø³Ø·ØŒ ÙŠØ­ØªØ§Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©)
        return {
            "question": f"Sample {q_type} question?",
            "correct_answer": "Sample Answer",
            "wrong_answers": ["Wrong 1", "Wrong 2", "Wrong 3"],
            "explanation": "Brief explanation",
            "image_description": f"{q_type} related background image"
        }
    
    def _generate_local_question(self, q_type: str, difficulty: str) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ø³Ø¤Ø§Ù„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø­Ù„ÙŠØ©"""
        # Ù‚Ø§Ø¹Ø¯Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        questions_db = {
            "flag_identification": [
                {
                    "question": "Which country does this flag belong to?",
                    "correct_answer": "Japan",
                    "wrong_answers": ["China", "South Korea", "Thailand"],
                    "explanation": "Red circle on white background",
                    "image_description": "Japanese flag simple design"
                }
            ],
            "general_knowledge": [
                {
                    "question": "What is the largest planet in our solar system?",
                    "correct_answer": "Jupiter",
                    "wrong_answers": ["Saturn", "Neptune", "Earth"],
                    "explanation": "11 times wider than Earth",
                    "image_description": "Jupiter planet in space"
                }
            ],
            # ... Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
        }
        
        if q_type in questions_db and questions_db[q_type]:
            return random.choice(questions_db[q_type])
        
        # Ø³Ø¤Ø§Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯
        return {
            "question": "What is the capital of France?",
            "correct_answer": "Paris",
            "wrong_answers": ["London", "Berlin", "Madrid"],
            "explanation": "City of Light in Europe",
            "image_description": "Eiffel Tower Paris landscape"
        }
    
    def _generate_hashtags(self, q_type: str, difficulty: str) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª Ù…Ù†Ø§Ø³Ø¨Ø©"""
        base_tags = ["Quiz", "Challenge", "TestYourBrain"]
        
        type_tags = {
            "flag_identification": ["Flags", "Countries", "Geography"],
            "general_knowledge": ["Trivia", "Knowledge", "Facts"],
            "landmark_recognition": ["Landmarks", "Travel", "World"],
            "country_from_image": ["Geography", "Countries", "Culture"]
        }
        
        difficulty_tags = {
            "easy": ["EasyQuiz", "FunFacts"],
            "medium": ["BrainTeaser", "ThinkFast"],
            "hard": ["GeniusTest", "HardChallenge"]
        }
        
        tags = base_tags + type_tags.get(q_type, []) + difficulty_tags.get(difficulty, [])
        return tags[:8]  # Ø§Ù„Ø­Ø¯ Ø¥Ù„Ù‰ 8 Ù‡Ø§Ø´ØªØ§Ø¬Ø§Øª
    
    def generate_metadata(self, question_data: Dict, video_number: int) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ÙŠØªØ§Ø¯Ø§ØªØ§ ÙƒØ§Ù…Ù„Ø© Ù„Ù„ÙÙŠØ¯ÙŠÙˆ"""
        title = METADATA_TEMPLATES["title"].format(
            question_type=question_data["question_type"].replace("_", " ").title(),
            number=video_number,
            seconds=CHANNEL_CONFIG["countdown_duration"]
        )
        
        description = METADATA_TEMPLATES["description"].format(
            difficulty=question_data["difficulty"],
            seconds=CHANNEL_CONFIG["countdown_duration"],
            hashtags=" ".join([f"#{tag}" for tag in question_data["hashtags"][:5]])
        )
        
        # ØªØ­Ø³ÙŠÙ† SEO Ù„Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
        title = self._optimize_seo(title)
        
        return {
            "title": title,
            "description": description,
            "tags": METADATA_TEMPLATES["tags"] + question_data["hashtags"],
            "category": "28",  # ØªØ¹Ù„ÙŠÙ…
            "privacy": "private",  # Ø³ÙŠØªÙ… Ø¬Ø¯ÙˆÙ„ØªÙ‡
            "playlist_title": f"Daily Challenges {datetime.now().strftime('%B %Y')}"
        }
    
    def generate_compilation_metadata(self, shorts_count: int, day_date: str) -> Dict:
        """ØªÙˆÙ„ÙŠØ¯ Ù…ÙŠØªØ§Ø¯Ø§ØªØ§ Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ÙŠ"""
        return {
            "title": f"ğŸ¯ {shorts_count} Brain Challenges in 1 Minute | {day_date}",
            "description": f"""Can you solve all {shorts_count} challenges? 
Test your knowledge with today's quiz compilation!

ğŸ”¥ Daily quiz shorts
â± Quick brain exercises
ğŸ§  Test your intelligence

#QuizCompilation #DailyChallenge #BrainWorkout #ShortsCompilation""",
            "tags": ["Compilation", "Quiz", "Challenge", "Shorts", "Daily"],
            "category": "28",
            "privacy": "private"
        }
    
    def _optimize_seo(self, title: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„Ù€ SEO"""
        # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©
        keywords = ["Quiz", "Challenge", "Test", "Quick", "Brain", "Shorts"]
        
        words = title.split()
        if len(words) < 8:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù‚ØµÙŠØ±Ø§Ù‹
            # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©
            for keyword in keywords:
                if keyword.lower() not in title.lower():
                    title = f"{title} | {keyword}"
                    break
        
        # Ø¶Ø¨Ø· Ø§Ù„Ø·ÙˆÙ„
        if len(title) > 70:
            title = title[:67] + "..."
        
        return title
